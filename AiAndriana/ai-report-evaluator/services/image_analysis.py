from torchvision import transforms
from PIL import Image
import torch
from models.analysis_result import AnalysisResult

# Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Ï€ÏÎ¿ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Î¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï…
from torchvision.models import resnet18, ResNet18_Weights

weights = ResNet18_Weights.DEFAULT
model = resnet18(weights=weights)
model.eval()


# Î ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± ÎµÎ¹ÎºÏŒÎ½Î±Ï‚ (ÏŒÏ€Ï‰Ï‚ Î±Ï€Î±Î¹Ï„ÎµÎ¯Ï„Î±Î¹ Î±Ï€ÏŒ Ï„Î¿ resnet)
preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

# Dummy mapping (ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¬ Î¸Î± Î²Î¬Î¶Î±Î¼Îµ ImageNet labels Î® custom Î´Î¹ÎºÎ­Ï‚ ÏƒÎ¿Ï…)
acceptable_keywords = ["fire", "emergency", "disaster", "smoke", "accident", "volcano"]
unacceptable_keywords = ["meme", "cartoon", "person", "nude", "naked", "dog", "cat"]

def classify_image(image_path):
    image = Image.open(image_path).convert("RGB")
    input_tensor = preprocess(image).unsqueeze(0)  # batch size = 1

    with torch.no_grad():
        output = model(input_tensor)
        predicted_idx = torch.argmax(output[0]).item()

    # ÎšÎ±Ï„Î­Î²Î±ÏƒÎµ Ï„Î± labels (Î¼ÏŒÎ½Î¿ Ï„Î·Î½ 1Î· Ï†Î¿ÏÎ¬ â€” Î® Ï„Î¿Ï€Î¿Î¸Î­Ï„Î·ÏƒÎ­ Ï„Î± Ï„Î¿Ï€Î¹ÎºÎ¬)
    from urllib.request import urlopen
    labels_url = "https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
    with urlopen(labels_url) as f:
        categories = [line.strip().decode("utf-8") for line in f.readlines()]

    label = categories[predicted_idx]
    return label.lower()

def analyze_images(image_paths):
    for path in image_paths:
        label = classify_image(path)
        print(f"ğŸ“· Î‘Î½Î¬Î»Ï…ÏƒÎ· ÎµÎ¹ÎºÏŒÎ½Î±Ï‚: {path} â†’ '{label}'")

        if any(bad in label for bad in unacceptable_keywords):
            return AnalysisResult(relevant=False, confidence=0.9, summary=label)  # high confidence, rejected

        if any(good in label for good in acceptable_keywords):
            continue  # keep checking next images

        # Î¬Î³Î½Ï‰ÏƒÏ„Î· ÎºÎ±Ï„Î·Î³Î¿ÏÎ¯Î± = Î±Ï€ÏŒÏÏÎ¹ÏˆÎ· Î¼Îµ Ï‡Î±Î¼Î·Î»Î® ÎµÎ¼Ï€Î¹ÏƒÏ„Î¿ÏƒÏÎ½Î·
        return AnalysisResult(relevant=False, confidence=0.3, summary=label)

    # Î±Î½ ÏŒÎ»ÎµÏ‚ Î¿Î¹ ÎµÎ¹ÎºÏŒÎ½ÎµÏ‚ ÎµÎ¯Î½Î±Î¹ Î±Ï€Î¿Î´ÎµÎºÏ„Î­Ï‚
    return AnalysisResult(relevant=True, confidence=1.0, summary="valid_images")